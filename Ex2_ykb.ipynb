{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "therapeutic-trigger",
   "metadata": {},
   "source": [
    "# 손글씨 이미지 데이터 분류문제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "necessary-maine",
   "metadata": {},
   "source": [
    "# 1. Feature Data 와 Label Data분석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spare-power",
   "metadata": {},
   "source": [
    "## 1.1 Feature Data 파악"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "acute-security",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature shape: (1797, 64)\n",
      "Feature name:  ['pixel_0_0', 'pixel_0_1', 'pixel_0_2', 'pixel_0_3', 'pixel_0_4', 'pixel_0_5', 'pixel_0_6', 'pixel_0_7', 'pixel_1_0', 'pixel_1_1', 'pixel_1_2', 'pixel_1_3', 'pixel_1_4', 'pixel_1_5', 'pixel_1_6', 'pixel_1_7', 'pixel_2_0', 'pixel_2_1', 'pixel_2_2', 'pixel_2_3', 'pixel_2_4', 'pixel_2_5', 'pixel_2_6', 'pixel_2_7', 'pixel_3_0', 'pixel_3_1', 'pixel_3_2', 'pixel_3_3', 'pixel_3_4', 'pixel_3_5', 'pixel_3_6', 'pixel_3_7', 'pixel_4_0', 'pixel_4_1', 'pixel_4_2', 'pixel_4_3', 'pixel_4_4', 'pixel_4_5', 'pixel_4_6', 'pixel_4_7', 'pixel_5_0', 'pixel_5_1', 'pixel_5_2', 'pixel_5_3', 'pixel_5_4', 'pixel_5_5', 'pixel_5_6', 'pixel_5_7', 'pixel_6_0', 'pixel_6_1', 'pixel_6_2', 'pixel_6_3', 'pixel_6_4', 'pixel_6_5', 'pixel_6_6', 'pixel_6_7', 'pixel_7_0', 'pixel_7_1', 'pixel_7_2', 'pixel_7_3', 'pixel_7_4', 'pixel_7_5', 'pixel_7_6', 'pixel_7_7']\n",
      "data: [ 0.  0.  5. 13.  9.  1.  0.  0.  0.  0. 13. 15. 10. 15.  5.  0.  0.  3.\n",
      " 15.  2.  0. 11.  8.  0.  0.  4. 12.  0.  0.  8.  8.  0.  0.  5.  8.  0.\n",
      "  0.  9.  8.  0.  0.  4. 11.  0.  1. 12.  7.  0.  0.  2. 14.  5. 10. 12.\n",
      "  0.  0.  0.  0.  6. 13. 10.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits=load_digits()\n",
    "digits_data=digits['data']\n",
    "print(\"Feature shape:\",digits_data.shape)\n",
    "print(\"Feature name: \",digits['feature_names'])\n",
    "print(\"data:\",digits_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lasting-speed",
   "metadata": {},
   "source": [
    "### 해석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prepared-village",
   "metadata": {},
   "source": [
    " ### - feature는 손글씨 이미지로 8x8 이미지가 64장 있는것을 shape를 보고 알수있다.\n",
    " ### - feature의 이름을 보면 각 feature는 각 셀의 값을 나타내며 이름은 pixel행_열로 표현한 것을 볼수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chinese-tonight",
   "metadata": {},
   "source": [
    "## 1.2 Label 파악"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "amateur-nebraska",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label shape: (1797,)\n",
      "Label name:  [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "digits_label=digits.target\n",
    "print(\"Label shape:\",digits_label.shape)\n",
    "print(\"Label name: \",digits['target_names'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "urban-appliance",
   "metadata": {},
   "source": [
    " ## 해석\n",
    " ### - Label은 데이터개수와 같게 1797개 가 있으며 .\n",
    " ### - Label 이름은 숫자 0,1,2,3,4,5,6,7,8,9를 의미함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vanilla-appreciation",
   "metadata": {},
   "source": [
    "## 2. 5가지 모델 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "confused-nightlife",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t Decision_tree Result\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        43\n",
      "           1       0.81      0.81      0.81        42\n",
      "           2       0.79      0.82      0.80        40\n",
      "           3       0.79      0.91      0.85        34\n",
      "           4       0.83      0.95      0.89        37\n",
      "           5       0.90      0.96      0.93        28\n",
      "           6       0.84      0.93      0.88        28\n",
      "           7       0.96      0.82      0.89        33\n",
      "           8       0.88      0.65      0.75        43\n",
      "           9       0.78      0.78      0.78        32\n",
      "\n",
      "    accuracy                           0.86       360\n",
      "   macro avg       0.86      0.86      0.86       360\n",
      "weighted avg       0.86      0.86      0.85       360\n",
      "\n",
      "\t\t Random_forest Result\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        43\n",
      "           1       0.93      1.00      0.97        42\n",
      "           2       1.00      1.00      1.00        40\n",
      "           3       1.00      1.00      1.00        34\n",
      "           4       0.93      1.00      0.96        37\n",
      "           5       0.90      0.96      0.93        28\n",
      "           6       1.00      0.96      0.98        28\n",
      "           7       0.94      0.97      0.96        33\n",
      "           8       1.00      0.84      0.91        43\n",
      "           9       0.94      0.94      0.94        32\n",
      "\n",
      "    accuracy                           0.96       360\n",
      "   macro avg       0.96      0.96      0.96       360\n",
      "weighted avg       0.97      0.96      0.96       360\n",
      "\n",
      "\t\t Svm_model Result\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       0.95      1.00      0.98        42\n",
      "           2       1.00      1.00      1.00        40\n",
      "           3       1.00      1.00      1.00        34\n",
      "           4       1.00      1.00      1.00        37\n",
      "           5       0.93      1.00      0.97        28\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        33\n",
      "           8       1.00      0.93      0.96        43\n",
      "           9       1.00      0.97      0.98        32\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n",
      "\t\t Sgd_model Result\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       0.86      0.90      0.88        42\n",
      "           2       1.00      1.00      1.00        40\n",
      "           3       0.91      0.94      0.93        34\n",
      "           4       1.00      0.97      0.99        37\n",
      "           5       0.93      0.96      0.95        28\n",
      "           6       0.96      0.93      0.95        28\n",
      "           7       0.97      0.97      0.97        33\n",
      "           8       0.93      0.93      0.93        43\n",
      "           9       0.93      0.88      0.90        32\n",
      "\n",
      "    accuracy                           0.95       360\n",
      "   macro avg       0.95      0.95      0.95       360\n",
      "weighted avg       0.95      0.95      0.95       360\n",
      "\n",
      "\t\t Logistic_model Result\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       0.95      0.95      0.95        42\n",
      "           2       0.98      1.00      0.99        40\n",
      "           3       0.94      0.97      0.96        34\n",
      "           4       1.00      1.00      1.00        37\n",
      "           5       0.79      0.96      0.87        28\n",
      "           6       1.00      0.96      0.98        28\n",
      "           7       0.94      0.97      0.96        33\n",
      "           8       0.92      0.81      0.86        43\n",
      "           9       0.97      0.88      0.92        32\n",
      "\n",
      "    accuracy                           0.95       360\n",
      "   macro avg       0.95      0.95      0.95       360\n",
      "weighted avg       0.95      0.95      0.95       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "decision_tree = DecisionTreeClassifier(random_state=32)\n",
    "random_forest = RandomForestClassifier(random_state=32)\n",
    "svm_model = svm.SVC()\n",
    "sgd_model = SGDClassifier()\n",
    "logistic_model = LogisticRegression(max_iter=10000)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits_data, \n",
    "                                                    digits_label, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=7)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model=[decision_tree,random_forest,svm_model,sgd_model,logistic_model]\n",
    "model_name=['Decision_tree','Random_forest','Svm_model','Sgd_model','Logistic_model']\n",
    "\n",
    "for i in range(5):\n",
    "    model[i].fit(X_train, y_train)\n",
    "    y_pred =model[i].predict(X_test)\n",
    "    print(\"\\t\\t {} Result\\n\".format(model_name[i]))\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceramic-translator",
   "metadata": {},
   "source": [
    " ## 결과 분석\n",
    " \n",
    " ### -손글씨 분류문제는 FP(False Positive),FN(False Negative)의 중요도가 비슷하다고 생각합니다. (FP의 경우 정답숫자와 다른 숫자를 정답으로 분류하는 경우를 의미하고 FN은 정답숫자를 다른 숫자로 분류하는 것을 의미합니다.) 예를 들어 생각해보면 이 분류기가 통장 계좌번호를 인식한다고 생각해보면 정답숫자를 오답숫자로 인식하든 오답 숫자를 정답숫자로 인식하든 어느 경우에도 인식한 계좌번호가 달라집니다. 또한 이 분류기가 어떤 도메인에 활용되는지 정해지지 않았으므로 FP와 FN이 도메인에 미치는 영향을 잘 파악할 수 없었습니다. 따라서 Precision, Recall, Accuracy 모두 중요한 지표인 것 같다고 생각했습니다.\n",
    " \n",
    " ### - 다섯가지 분류모델에 대해 손글씨 데이터를 분석한 결과는 위와 같습니다. 가장 성능이 좋은 결과는 svm(precision:0.99,recall:0.99,f1-score:0.99)으로 다른 모델에 비해 모든 지표값이 높으므로 이 분류 모델이 적합하다고 생각합니다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hired-deficit",
   "metadata": {},
   "source": [
    "# 와인 분류문제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worse-accordance",
   "metadata": {},
   "source": [
    "# 1. Feature Data 와 Label Data분석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocal-competition",
   "metadata": {},
   "source": [
    "## 1.1 Feature Data 파악"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "agreed-wiring",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature shape: (178, 13)\n",
      "Feature name:  ['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n",
      "data: [1.423e+01 1.710e+00 2.430e+00 1.560e+01 1.270e+02 2.800e+00 3.060e+00\n",
      " 2.800e-01 2.290e+00 5.640e+00 1.040e+00 3.920e+00 1.065e+03]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "wine=load_wine()\n",
    "wine_data=wine.data\n",
    "print(\"Feature shape:\",wine.data.shape)\n",
    "print(\"Feature name: \",wine['feature_names'])\n",
    "print(\"data:\",wine_data[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italic-racing",
   "metadata": {},
   "source": [
    "### 해석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vertical-sunrise",
   "metadata": {},
   "source": [
    " ### - feature는 와인의 특성으로 shape을 보면 178개의 와인과 그 특성이 있음을 알 수있습니다.\n",
    " ### - feature의 이름을 보면 13개의 특성이 있고 각 이름을 알 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "following-exception",
   "metadata": {},
   "source": [
    "## 1.2 Label 파악"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "spectacular-impression",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label shape: (178,)\n",
      "Label name:  ['class_0' 'class_1' 'class_2']\n"
     ]
    }
   ],
   "source": [
    "wine_label=wine.target\n",
    "print(\"Label shape:\",wine_label.shape)\n",
    "print(\"Label name: \",wine['target_names'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indian-camcorder",
   "metadata": {},
   "source": [
    " ## 해석\n",
    " ### - Label은 데이터개수와 같게 178개 가 있습니다 .\n",
    " ### - Label 이름은 와인의 등급을 의미합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "considerable-peter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t Decision_tree Result\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.89      1.00      0.94        17\n",
      "           2       1.00      0.83      0.91        12\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.96      0.94      0.95        36\n",
      "weighted avg       0.95      0.94      0.94        36\n",
      "\n",
      "\t\t Random_forest Result\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       1.00      1.00      1.00        17\n",
      "           2       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n",
      "\t\t Svm_model Result\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86         7\n",
      "           1       0.58      0.88      0.70        17\n",
      "           2       0.33      0.08      0.13        12\n",
      "\n",
      "    accuracy                           0.61        36\n",
      "   macro avg       0.59      0.61      0.56        36\n",
      "weighted avg       0.55      0.61      0.54        36\n",
      "\n",
      "\t\t Sgd_model Result\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      1.00      0.48         7\n",
      "           1       1.00      0.12      0.21        17\n",
      "           2       0.25      0.25      0.25        12\n",
      "\n",
      "    accuracy                           0.33        36\n",
      "   macro avg       0.52      0.46      0.31        36\n",
      "weighted avg       0.62      0.33      0.28        36\n",
      "\n",
      "\t\t Logistic_model Result\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.94      1.00      0.97        17\n",
      "           2       1.00      0.92      0.96        12\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.98      0.97      0.98        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "decision_tree = DecisionTreeClassifier(random_state=32)\n",
    "random_forest = RandomForestClassifier(random_state=88)\n",
    "svm_model = svm.SVC()\n",
    "sgd_model = SGDClassifier()\n",
    "logistic_model = LogisticRegression(max_iter=10000)\n",
    "\n",
    "wine=load_wine()\n",
    "wine_data=wine.data\n",
    "wine_label=wine.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine_data, \n",
    "                                                    wine_label, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=7)\n",
    "\n",
    "\n",
    "\n",
    "model=[decision_tree,random_forest,svm_model,sgd_model,logistic_model]\n",
    "model_name=['Decision_tree','Random_forest','Svm_model','Sgd_model','Logistic_model']\n",
    "for i in range(5):\n",
    "    model[i].fit(X_train, y_train)\n",
    "    y_pred =model[i].predict(X_test)\n",
    "    print(\"\\t\\t {} Result\\n\".format(model_name[i]))\n",
    "    print(classification_report(y_test, y_pred,labels=np.unique(y_pred)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "level-prompt",
   "metadata": {},
   "source": [
    " ## 결과 분석\n",
    " \n",
    " ### -와인등급 분류문제도 FP(False Positive),FN(False Negative)의 중요도가 비슷하다고 생각합니다. 예를 들어 와인을 판매하는 입장에서 생각해보면 높은 등급을 낮은 등급으로 판단했을때는 높은 가격의 와인을 낮은 가격으로 팔아서 매출에 영향을 주게 됩니다. 낮은 등급의 와인을 높은 등급으로 판단하면 고객의 항의가 많아 질것으로 예상되 매출에 영향을 줄 것으로 생각됩니다. 이 분류기 또한 어떤 도메인에 활용되는지 정해지지 않았으므로 FP와 FN이 도메인에 미치는 영향을 잘 파악할 수 없었습니다. 따라서 Precision, Recall, Accuracy 모두 중요한 지표인 것 같다고 생각했습니다.\n",
    " \n",
    " ### - 다섯가지 분류모델에 대해 와인 분류 데이터를 분석한 결과는 위와 같습니다. 가장 성능이 좋은 결과는 Random Forest Result(precision:1,recall:1,f1-score:1)으로 다른 모델에 비해 모든 지표값이 높으므로 이 분류 모델이 적합하다고 생각합니다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coated-spider",
   "metadata": {},
   "source": [
    "# 유방암 진단 문제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "every-morris",
   "metadata": {},
   "source": [
    "# 1. Feature Data 와 Label Data분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "suitable-trash",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature shape: (569, 30)\n",
      "Feature name:  ['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
      "data: [1.799e+01 1.038e+01 1.228e+02 1.001e+03 1.184e-01 2.776e-01 3.001e-01\n",
      " 1.471e-01 2.419e-01 7.871e-02 1.095e+00 9.053e-01 8.589e+00 1.534e+02\n",
      " 6.399e-03 4.904e-02 5.373e-02 1.587e-02 3.003e-02 6.193e-03 2.538e+01\n",
      " 1.733e+01 1.846e+02 2.019e+03 1.622e-01 6.656e-01 7.119e-01 2.654e-01\n",
      " 4.601e-01 1.189e-01]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "breast=load_breast_cancer()\n",
    "breast_data=breast.data\n",
    "print(\"Feature shape:\",breast.data.shape)\n",
    "print(\"Feature name: \",breast['feature_names'])\n",
    "print(\"data:\",breast_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "warming-harmony",
   "metadata": {},
   "source": [
    "### 해석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regional-quarter",
   "metadata": {},
   "source": [
    " ### - feature는 와인의 특성으로 shape을 보면 569개의 와인과 그 특성이 있음을 알 수있습니다.\n",
    " ### - feature의 이름을 보면 30개의 특성이 있고 각 이름을 알 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaning-highlight",
   "metadata": {},
   "source": [
    "## 1.2 Label 파악"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "grave-brown",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label shape: (569,)\n",
      "Label name:  ['malignant' 'benign']\n"
     ]
    }
   ],
   "source": [
    "breast_label=breast.target\n",
    "print(\"Label shape:\",breast_label.shape)\n",
    "print(\"Label name: \",breast['target_names'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dangerous-tissue",
   "metadata": {},
   "source": [
    " ## 해석\n",
    " ### - Label은 데이터개수와 같게 178개 가 있습니다 .\n",
    " ### - Label 이름은 악성과 음성을 의미합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "split-utilization",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t Decision_tree Result\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.82      0.87        40\n",
      "           1       0.91      0.96      0.93        74\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.91      0.89      0.90       114\n",
      "weighted avg       0.91      0.91      0.91       114\n",
      "\n",
      "\t\t Random_forest Result\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        40\n",
      "           1       1.00      1.00      1.00        74\n",
      "\n",
      "    accuracy                           1.00       114\n",
      "   macro avg       1.00      1.00      1.00       114\n",
      "weighted avg       1.00      1.00      1.00       114\n",
      "\n",
      "\t\t Svm_model Result\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.72      0.84        40\n",
      "           1       0.87      1.00      0.93        74\n",
      "\n",
      "    accuracy                           0.90       114\n",
      "   macro avg       0.94      0.86      0.89       114\n",
      "weighted avg       0.92      0.90      0.90       114\n",
      "\n",
      "\t\t Sgd_model Result\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.97      0.76        40\n",
      "           1       0.98      0.68      0.80        74\n",
      "\n",
      "    accuracy                           0.78       114\n",
      "   macro avg       0.80      0.83      0.78       114\n",
      "weighted avg       0.85      0.78      0.79       114\n",
      "\n",
      "\t\t Logistic_model Result\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.85      0.92        40\n",
      "           1       0.93      1.00      0.96        74\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.96      0.93      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "decision_tree = DecisionTreeClassifier(random_state=32)\n",
    "random_forest = RandomForestClassifier(random_state=32)\n",
    "svm_model = svm.SVC()\n",
    "sgd_model = SGDClassifier()\n",
    "logistic_model = LogisticRegression(max_iter=10000)\n",
    "\n",
    "breast=load_breast_cancer()\n",
    "breast_data=breast.data\n",
    "breast_label=breast.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(breast_data,\n",
    "                                                    breast_label, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=7)\n",
    "\n",
    "\n",
    "\n",
    "model=[decision_tree,random_forest,svm_model,sgd_model,logistic_model]\n",
    "model_name=['Decision_tree','Random_forest','Svm_model','Sgd_model','Logistic_model']\n",
    "for i in range(5):\n",
    "    model[i].fit(X_train, y_train)\n",
    "    y_pred =model[i].predict(X_test)\n",
    "    print(\"\\t\\t {} Result\\n\".format(model_name[i]))\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "central-equilibrium",
   "metadata": {},
   "source": [
    " ## 결과 분석\n",
    " \n",
    " ### -유방암 진단문제는 FN(False Negative)의 중요도가 FP(False Positive) 보다 중요하다고 생각합니다. 왜냐하면 암이 아닌환자가 암진단을 맞을 경우에는 다시 검사 하는 과정에서 암이 아닌것으로 판단될 확률이 높으며 이는 약간의 돈의 낭비가 있을 것입니다. 반대로 암인 환자가 암이 아니게 나올 경우 이 환자는 자기가 암이 아닌 것으로 생각하고 있다가 암이 더 진행되서 다시 병원에 오게되므로 생존률의 급격한 저하가 올 것입니다. 환자의 생명이 더 중요하므로 FN이 낮은, 즉 Recall이 높은 지표가  좋은 지표가 되겠습니다.\n",
    " \n",
    " ### - 다섯가지 분류모델에 대해 유방암 진단 데이터를 분석한 결과는 위와 같습니다. 가장 성능이 좋은 결과는 Random Forest Result(precision:1,recall:1,f1-score:1)으로 다른 모델에 비해 모든 지표값이 높으므로 이 분류 모델이 적합하다고 생각합니다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designing-hygiene",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
